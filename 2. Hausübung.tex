\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}

\renewcommand{\thesection}{Aufgabe \arabic{section}}
\renewcommand{\thesubsection}{\alph{subsection})}

\renewcommand{\thesubsubsection}{\roman{subsubsection})}

\newcommand{\dx}{\frac{\mathrm{d}}{\mathrm{d}x}}
\newcommand{\dxx}{\frac{\mathrm{d}^2}{\mathrm{d}x^2}}

\title{II. Hausübung „Wahrscheinlichkeiten“}
\author{Henrik Kröger}
\date{\today}

\begin{document}
\maketitle

\section{(Erzeugende Funktion)}
Die (gewöhnliche) erzeugende Funktion
einer diskreten Wahrscheinlichkeitsverteilung $p(n)$
für eine Zufallsvariablen $n\in\mathbb{N}$ ist definiert durch
\begin{equation}
    g_p(x) := \sum_{n=0}^{\infty} x^n p(n)
\end{equation}

\subsection{Erwartungswert und Varianz durch $g(x)$ ausgedrückt}
\subsubsection{Erwartungswert}
Der Erwartungswert ist allgemein definiert als
\begin{equation}
    \langle p \rangle := \sum_{n=0}^{\infty} n \, p(n)
\end{equation}
Wir vergleichen die Terme des Erwartungswertes mit denen der Erzeugenden Funktion:
\begin{align*}
    \langle p \rangle &= 0\;\;\,p(0)   + 1\;\;\,p(1) + 2\;\;\,p(2) + 3\;\;\,p(3) + 4\;\;\,p(4) + \ldots \\
    g_p(x)            &= x^0\,p(0) + x^1\,p(1) + x^2\,p(2) + x^3\,p(3) + x^4\,p(4) + \ldots
\end{align*}
$\langle p \rangle$ hat offenbar Ähnlichkeit mit der ersten Ableitung $g_p'(x)$ von $g(x)$:
\begin{align*}
    \langle p \rangle &= 0\,p(0) + 1\,p(1) + 2\;\;\,p(2) + 3\;\;\;\,p(3) + 4\;\;\;\,p(4) + \ldots \\
    g_p'(x)           &= 0\,p(0) + 1\,p(1) + 2x\,p(2) +    3x^2\,p(3)    + 4x^3\,p(4) + \ldots
\end{align*}
Es stören noch die $x$ in $g_p'(x)$, die aber durch Einsetzen von $x=1$ verschwinden:
\begin{align*}
    \langle p \rangle &= 0\,p(0) + 1\,p(1) + 2\,p(2) + 3\,p(3) + 4\,p(4) + \ldots \\
    g_p'(1)           &= 0\,p(0) + 1\,p(1) + 2\,p(2) + 3\,p(3) + 4\,p(4) + \ldots \\
\end{align*}

Nach dem dies zur richtigen Idee geführt hat,
kann dies noch in besserer Schreibweise bewiesen werden:
\begin{equation}
    g_p'(1) = \dx \sum_{n=0}^\infty x^n \, p(n) \Big|_{x=1}
            =     \sum_{n=0}^\infty n x^{n-1} \, p(n) \Big|_{x=1}
            =     \sum_{n=0}^\infty n \, p(n)
            = \langle p \rangle
\end{equation}


\subsubsection{Varianz}
Die Varianz ist allgemein definiert als
\begin{equation}
    \sigma_p^2 := \langle p^2 \rangle - \langle p \rangle^2
\end{equation}
$\langle p \rangle^2$ ist schon als $g_p'(1)^2$ bekannt,
$\langle p^2 \rangle$ aber ist:
\begin{equation}
    \langle p^2 \rangle = \sum_{n=0}^\infty n^2 p(n)
\end{equation}

Hat es vielleicht diesmal etwas mit der zweiten Ableitung zu tun?
$n^2$ deutet darauf hin. Wir betrachten die zweite Ableitung der Erzeugenden
an der Stelle $x=1$:
\begin{align*}
    g_p''(1) &= \dxx \sum_{n=0}^\infty x^n \, p(n) \Big|_{x=1}
             = \sum_{n=0}^\infty n(n-1) x^{n-2} \, p(n) \Big|_{x=1} \\
             &= \sum_{n=0}^\infty (n^2 - n) \, p(n)
             = \sum_{n=0}^\infty n^2 p(n) - \sum_{n=0}^\infty n p(n)
             = \langle p^2 \rangle - \langle p \rangle
\end{align*}
Das ist schon \emph{fast} die Definition der Varianz.
Lediglich $\langle p \rangle$ sollte $\langle p \rangle^2$ sein:
\begin{align*}
    g''(1) &= \langle p^2 \rangle - \langle p \rangle \\
    g''(1) + \langle p \rangle - \langle p \rangle^2  &= \langle p^2 \rangle - \langle p \rangle + \langle p \rangle - \langle p \rangle^2 = \langle p^2 \rangle - \langle p \rangle^2 = \sigma_p^2 \\
    g''(1) + g'(1) - g'(1)^2 &= \sigma_p^2
\end{align*}

Wir haben also erhalten, dass:
{\boldmath
\begin{align}
    \langle p \rangle &= g'(1) \label{eq:erwartungswert} \\
    \sigma_p^2 &= g''(1) + g'(1) - g'(1)^2 \label{eq:varianz}
\end{align}}

\newpage
\subsection{Erzeugende Funktionen der Poisson- und der Binomialverteilung}
\subsubsection{Poissonverteilung}
Die Poissonverteilung ist definiert als:
\begin{equation}
    P_\lambda (k) = \frac{\lambda^k}{k!}\, \mathrm{e}^{-\lambda}
\end{equation}
Unter Benutzung der Reihenentwicklung für die e-Funktion erhalten wir
für die erzeugende Funktion der Poissonverteilung:
\begin{equation}
    g_{P_\lambda}(x) = \sum_{k=0}^\infty x^k \frac{\lambda^k}{k!} \mathrm{e}^{-\lambda}
                     = \mathrm{e}^{-\lambda} \sum_{k=0}^\infty \frac{(x\lambda)^k}{k!}
                     = \mathrm{e}^{-\lambda} \mathrm{e}^{x\lambda}
                     = \mathrm{e}^{\lambda (x-1)}
\end{equation}

Nach (\ref{eq:erwartungswert}) ergibt sich für den Erwartungswert:
\begin{equation}
    \langle P_\lambda \rangle = g'_{P_\lambda}(1)
    = \dx \mathrm{e}^{\lambda (x-1)} \Big|_{x=1}
    = \lambda \; \mathrm{e}^{\lambda (x-1)} \Big|_{x=1}
    = \lambda
\end{equation}

Für die Varianz berechnen wir zuerst $g_{P_\lambda}''(1)$:
\begin{equation}
    g_{P_\lambda}''(1) = \lambda^2 \mathrm{e}^{\lambda (x-1)} \Big|_{x=1}
                       = \lambda^2
\end{equation}
Einsetzen in die Formel (\ref{eq:varianz}) ergibt dann:
\begin{align*}
    \sigma_{P_\lambda}^2 &= g''(1) + g'(1) - g'(1)^2 \\
                         &= \lambda^2 + \lambda - \lambda^2 = \lambda
\end{align*}

\subsubsection{Binomialverteilung}

\end{document}
